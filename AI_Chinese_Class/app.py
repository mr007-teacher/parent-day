import streamlit as st
import azure.cognitiveservices.speech as speechsdk
import firebase_admin
from firebase_admin import credentials, firestore
from datetime import datetime
import google.generativeai as genai
from audio_recorder_streamlit import audio_recorder
import os
import json

# ================= ç½‘é¡µè®¾ç½® =================
st.set_page_config(page_title="AI æœ—è¯»å°åŠ©æ‰‹", page_icon="ğŸ¦œ")

# ================= ğŸ” å®‰å…¨è¯»å–å¯†é’¥ (äº‘ç«¯ç‰ˆ) =================
# è¿™æ®µä»£ç ä¼šè‡ªåŠ¨å» Streamlit çš„ä¿é™©ç®±é‡Œæ‰¾é’¥åŒ™
try:
    SPEECH_KEY = st.secrets["SPEECH_KEY"]
    SPEECH_REGION = st.secrets["SPEECH_REGION"]
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
    # Firebase æ¯”è¾ƒç‰¹æ®Šï¼Œæˆ‘ä»¬æŠŠæ•´ä¸ª JSON å†…å®¹å­˜åœ¨ä¿é™©ç®±é‡Œ
    firebase_key_dict = json.loads(st.secrets["FIREBASE_KEY"])
except FileNotFoundError:
    st.error("âŒ å°šæœªé…ç½®äº‘ç«¯å¯†é’¥ï¼è¯·åœ¨ Streamlit åå°çš„ Secrets é‡Œå¡«å…¥å¯†é’¥ã€‚")
    st.stop()

# ================= åˆå§‹åŒ–æœåŠ¡ =================

# 1. é…ç½® Gemini
genai.configure(api_key=GEMINI_API_KEY)
# æ™ºèƒ½é€‰æ‹©æ¨¡å‹
valid_model = None
try:
    for m in genai.list_models():
        if 'generateContent' in m.supported_generation_methods and 'gemini' in m.name:
            valid_model = genai.GenerativeModel(m.name)
            break
except: pass
if valid_model is None: valid_model = genai.GenerativeModel('gemini-pro')

# 2. è¿æ¥ Firebase æ•°æ®åº“
if not firebase_admin._apps:
    try:
        cred = credentials.Certificate(firebase_key_dict)
        firebase_admin.initialize_app(cred)
    except Exception as e:
        st.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")

try:
    db = firestore.client()
except:
    db = None

# ================= åŠŸèƒ½å‡½æ•° =================

def analyze_audio_file(audio_filepath, reference_text):
    speech_config = speechsdk.SpeechConfig(subscription=SPEECH_KEY, region=SPEECH_REGION)
    speech_config.speech_recognition_language = "zh-CN"
    
    pronunciation_config = speechsdk.PronunciationAssessmentConfig(
        reference_text=reference_text,
        grading_system=speechsdk.PronunciationAssessmentGradingSystem.HundredMark,
        granularity=speechsdk.PronunciationAssessmentGranularity.Phoneme,
        enable_miscue=True
    )
    
    audio_config = speechsdk.audio.AudioConfig(filename=audio_filepath)
    recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)
    pronunciation_config.apply_to(recognizer)

    result = recognizer.recognize_once()
    return result

def get_ai_feedback(text, score):
    prompt = f"ä½ æ˜¯ä¸€ä½äº²åˆ‡çš„å°å­¦è¯­æ–‡è€å¸ˆã€‚å­¦ç”Ÿæœ—è¯»ï¼š'{text}'ã€‚å¾—åˆ†ï¼š{score}ã€‚è¯·ç»™ä¸€å¥50å­—ä»¥å†…çš„æš–å¿ƒè¯„è¯­ï¼ˆå¸¦emojiï¼‰ã€‚"
    try:
        response = valid_model.generate_content(prompt)
        return response.text
    except: return "è€å¸ˆæ­£åœ¨æ€è€ƒä¸­...ğŸ‘"

def save_to_firebase(student_name, text, score, comment):
    if db:
        db.collection("class_scores").add({
            "name": student_name, "text": text, "score": score, "ai_comment": comment, "timestamp": datetime.now()
        })

# ================= ç½‘é¡µç•Œé¢ =================

st.title("ğŸ¦œ AI æœ—è¯»è¯„åˆ†ç³»ç»Ÿ")

with st.sidebar:
    st.header("ğŸ“ å­¦ç”Ÿä¿¡æ¯")
    student_name = st.text_input("è¯·è¾“å…¥ä½ çš„åå­—ï¼š", "")
    if st.button("åˆ·æ–°æ’è¡Œæ¦œ"): st.rerun()
    if db: st.success("â˜ï¸ äº‘ç«¯è¿æ¥æ­£å¸¸")

st.markdown("### ğŸ“– ç¬¬ä¸€æ­¥ï¼šç»ƒä¹ è¯¾æ–‡")
reference_text = st.text_area("è€å¸ˆè¦æŠŠå“ªæ®µè¯¾æ–‡æ”¾è¿™é‡Œï¼Ÿ", "ç™½æ—¥ä¾å±±å°½ï¼Œé»„æ²³å…¥æµ·æµã€‚æ¬²ç©·åƒé‡Œç›®ï¼Œæ›´ä¸Šä¸€å±‚æ¥¼ã€‚")

st.markdown("### ğŸ™ï¸ ç¬¬äºŒæ­¥ï¼šç‚¹å‡»å½•éŸ³")
audio_bytes = audio_recorder(text="", recording_color="#e8b62c", neutral_color="#6aa36f", icon_size="3x")

if audio_bytes:
    st.audio(audio_bytes, format="audio/wav")
    
    if st.button("ğŸ“¤ æäº¤ç»™è€å¸ˆè¯„åˆ†"):
        if not student_name:
            st.warning("ğŸ‘‰ è¯·å…ˆåœ¨å·¦ä¾§è¾“å…¥åå­—ï¼")
        else:
            with st.spinner("â˜ï¸ æ­£åœ¨ä¸Šä¼ å¹¶è¯„åˆ†..."):
                temp_filename = "temp_audio.wav"
                with open(temp_filename, "wb") as f:
                    f.write(audio_bytes)
                
                try:
                    result = analyze_audio_file(temp_filename, reference_text)
                    if result.reason == speechsdk.ResultReason.RecognizedSpeech:
                        score = speechsdk.PronunciationAssessmentResult(result).accuracy_score
                        
                        col1, col2 = st.columns(2)
                        with col1: st.metric("ä½ çš„å¾—åˆ†", f"{score:.0f}")
                        
                        ai_comment = get_ai_feedback(reference_text, score)
                        with col2: st.info(f"ğŸ‘©â€ğŸ« **AI è€å¸ˆè¯´ï¼š**\n\n{ai_comment}")
                        
                        if score > 90: st.balloons()
                        save_to_firebase(student_name, reference_text, score, ai_comment)
                        st.success("âœ… æˆç»©å·²ä¿å­˜ï¼")
                    else:
                        st.error("âŒ æ²¡å¬æ¸…ï¼Œè¯·å¤§å£°ä¸€ç‚¹ï¼")
                except Exception as e:
                    st.error(f"ç³»ç»Ÿé”™è¯¯: {e}")
                
                if os.path.exists(temp_filename): os.remove(temp_filename)

st.markdown("---")
st.subheader("ğŸ† ç­çº§å…‰è£æ¦œ")
if db:
    try:
        docs = db.collection("class_scores").order_by("timestamp", direction=firestore.Query.DESCENDING).limit(5).stream()
        data = [{"å­¦ç”Ÿ": d.to_dict().get('name'), "åˆ†æ•°": f"{d.to_dict().get('score'):.0f}", "è¯„è¯­": d.to_dict().get('ai_comment'), "æ—¶é—´": d.to_dict().get('timestamp').strftime("%H:%M")} for d in docs]
        if data: st.dataframe(data, hide_index=True)
    except: st.write("ç­‰å¾…æ•°æ®ä¸­...")